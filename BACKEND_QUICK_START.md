# OCTAåç«¯ä¼˜åŒ– - å¿«é€Ÿä½¿ç”¨æŒ‡å—

## ğŸš€ å¿«é€Ÿå¼€å§‹ï¼ˆ3æ­¥ï¼‰

### æ­¥éª¤1ï¼šå®‰è£…æ–°ä¾èµ–

```bash
cd octa_backend
pip install APScheduler>=3.10.0
```

### æ­¥éª¤2ï¼šå¯åŠ¨åç«¯

```bash
python main.py
```

**å¯åŠ¨æˆåŠŸæ ‡å¿—**ï¼š
```
======================================================================
                      OCTAå›¾åƒåˆ†å‰²åç«¯å¯åŠ¨ä¸­...
======================================================================
[INFO] é…ç½®æ¥æº: config/config.py
[INFO] æœåŠ¡åœ°å€: 127.0.0.1:8000
[SUCCESS] âœ“ æ–‡ä»¶ç®¡ç†è¡¨å·²å°±ç»ª
[SUCCESS] âœ“ å®šæ—¶æ¸…ç†ä»»åŠ¡å·²å¯åŠ¨
======================================================================
INFO:     Uvicorn running on http://127.0.0.1:8000
```

### æ­¥éª¤3ï¼šæµ‹è¯•æ¥å£

**å¥åº·æ£€æŸ¥**ï¼š
```bash
curl http://127.0.0.1:8000/
```

**å“åº”**ï¼š
```json
{
  "status": "ok",
  "message": "OCTA Image Segmentation API is running"
}
```

---

## ğŸ“ æ ¸å¿ƒAPIä½¿ç”¨

### 1. æƒé‡ä¸Šä¼ 

**è¯·æ±‚**ï¼š
```bash
curl -X POST "http://127.0.0.1:8000/api/v1/weight/upload" \
  -F "file=@unet_best.pth" \
  -F "model_type=unet"
```

**å“åº”**ï¼š
```json
{
  "code": 200,
  "msg": "æƒé‡ä¸Šä¼ æˆåŠŸ",
  "data": {
    "weight_id": "abc123def456",
    "file_id": 1,
    "file_name": "unet_best.pth",
    "file_size_mb": 45.67,
    "model_type": "unet",
    "metadata": {
      "total_params": 31042945,
      "total_keys": 234,
      "file_size_mb": 45.67
    }
  }
}
```

**æ ¡éªŒå¤±è´¥ç¤ºä¾‹**ï¼š
```json
{
  "detail": "æƒé‡æ ¡éªŒå¤±è´¥: æƒé‡æ–‡ä»¶ç¼ºå°‘å¿…éœ€çš„å±‚: enc1.conv1.weight, enc1.bn1.weightç­‰5ä¸ª"
}
```

---

### 2. æƒé‡åˆ—è¡¨æŸ¥è¯¢

**è¯·æ±‚**ï¼š
```bash
curl "http://127.0.0.1:8000/api/v1/weight/list?model_type=unet"
```

**å“åº”**ï¼š
```json
{
  "code": 200,
  "msg": "æŸ¥è¯¢æˆåŠŸ",
  "data": [
    {
      "weight_id": "abc123",
      "file_name": "unet_best.pth",
      "file_size_mb": 45.67,
      "model_type": "unet",
      "upload_time": "2026-01-27 10:30:00"
    }
  ]
}
```

---

### 3. å›¾åƒåˆ†å‰²é¢„æµ‹

**è¯·æ±‚**ï¼š
```bash
curl -X POST "http://127.0.0.1:8000/segment-octa/" \
  -F "file=@image.png" \
  -F "model_type=unet" \
  -F "weight_id=abc123"  # å¯é€‰ï¼Œé»˜è®¤ä½¿ç”¨å®˜æ–¹æƒé‡
```

**å“åº”**ï¼š
```json
{
  "code": 200,
  "msg": "åˆ†å‰²æˆåŠŸ",
  "data": {
    "mask_base64": "iVBORw0KGgoAAAANSUhEUgAAA...",
    "mask_url": "/results/image_seg.png",
    "inference_time": 0.125,
    "device": "cuda",
    "model_type": "unet",
    "weight_id": "abc123",
    "image_size": [512, 512]
  }
}
```

---

### 4. æƒé‡åˆ é™¤

**è¯·æ±‚**ï¼š
```bash
curl -X DELETE "http://127.0.0.1:8000/api/v1/weight/delete/abc123"
```

**å“åº”**ï¼š
```json
{
  "code": 200,
  "msg": "æƒé‡åˆ é™¤æˆåŠŸ"
}
```

---

## ğŸ” æ—¥å¿—æŸ¥çœ‹

### å®æ—¶æ—¥å¿—ç›‘æ§

**Linux/Mac**ï¼š
```bash
tail -f logs/octa_backend.log
```

**Windows PowerShell**ï¼š
```powershell
Get-Content logs\octa_backend.log -Wait -Tail 20
```

### æ—¥å¿—ç¤ºä¾‹

```
2026-01-27 10:30:45 - core.weight_validator - INFO - [æƒé‡æ ¡éªŒ] âœ“ æƒé‡æ–‡ä»¶æ ¡éªŒé€šè¿‡: unet_best.pth
2026-01-27 10:30:45 - service.weight_service - INFO - [æƒé‡ä¸Šä¼ ] âœ“ æˆåŠŸï¼Œweight_id=abc123, file_id=1
2026-01-27 10:30:46 - core.model_loader - INFO - [æ¨¡å‹åŠ è½½] âœ“ æƒé‡åŠ è½½æˆåŠŸï¼Œè®¾å¤‡: cuda
2026-01-27 10:30:46 - service.prediction_service - INFO - [é¢„æµ‹] âœ“ æ¨ç†å®Œæˆï¼Œè€—æ—¶=0.125ç§’
2026-01-27 02:00:00 - utils.cleanup_task - INFO - [æ¸…ç†ä»»åŠ¡] âœ“ å®Œæˆï¼Œåˆ é™¤ 12 ä¸ªæ–‡ä»¶ï¼Œé‡Šæ”¾ 45.67MB ç©ºé—´
```

---

## ğŸ› ï¸ é…ç½®è°ƒæ•´

### ä¿®æ”¹æ—¥å¿—çº§åˆ«

**æ–‡ä»¶**ï¼š`config/config.py`

```python
# å¼€å‘ç¯å¢ƒï¼šè¯¦ç»†æ—¥å¿—
LOG_LEVEL = "DEBUG"

# ç”Ÿäº§ç¯å¢ƒï¼šå…³é”®æ—¥å¿—
LOG_LEVEL = "INFO"

# ä»…é”™è¯¯æ—¥å¿—
LOG_LEVEL = "ERROR"
```

### è°ƒæ•´æ¸…ç†ç­–ç•¥

**æ–‡ä»¶**ï¼š`config/config.py`

```python
# ç¦ç”¨è‡ªåŠ¨æ¸…ç†
ENABLE_AUTO_CLEANUP = False

# è°ƒæ•´æ¸…ç†é—´éš”ï¼ˆ6å°æ—¶ï¼‰
CLEANUP_INTERVAL_SECONDS = 6 * 3600

# è°ƒæ•´è¿‡æœŸæ—¶é—´ï¼ˆ48å°æ—¶ï¼‰
FILE_EXPIRY_SECONDS = 48 * 3600
```

### ä¿®æ”¹æƒé‡å¤§å°é™åˆ¶

**æ–‡ä»¶**ï¼š`config/config.py`

```python
# å¢åŠ åˆ°500MB
WEIGHT_MAX_SIZE = 500 * 1024 * 1024
```

---

## ğŸ”§ æ•…éšœæ’æŸ¥

### é—®é¢˜1ï¼šæƒé‡æ ¡éªŒå¤±è´¥

**é”™è¯¯ä¿¡æ¯**ï¼š
```
æƒé‡æ ¡éªŒå¤±è´¥: æƒé‡æ–‡ä»¶ç¼ºå°‘å¿…éœ€çš„å±‚: enc1.conv1.weight...
```

**è§£å†³æ–¹æ¡ˆ**ï¼š
1. ç¡®è®¤æƒé‡æ–‡ä»¶æ˜¯U-Netæ¨¡å‹æƒé‡
2. æ£€æŸ¥æ˜¯å¦ä½¿ç”¨äº†ä¸åŒæ¶æ„çš„æ¨¡å‹
3. å°è¯•é‡æ–°è®­ç»ƒæˆ–ä½¿ç”¨å®˜æ–¹æƒé‡

---

### é—®é¢˜2ï¼šCUDAä¸å¯ç”¨

**æ—¥å¿—ä¿¡æ¯**ï¼š
```
[è®¾å¤‡é€‰æ‹©] âš  GPUä¸å¯ç”¨ï¼Œä½¿ç”¨CPU
```

**è§£å†³æ–¹æ¡ˆ**ï¼š
1. æ£€æŸ¥PyTorch CUDAå®‰è£…ï¼š`python -c "import torch; print(torch.cuda.is_available())"`
2. å®‰è£…CUDAç‰ˆæœ¬PyTorchï¼š`pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118`
3. CPUæ¨¡å¼ä¹Ÿå¯æ­£å¸¸ä½¿ç”¨ï¼Œä»…é€Ÿåº¦è¾ƒæ…¢

---

### é—®é¢˜3ï¼šæ¨¡å‹åŠ è½½å¤±è´¥

**é”™è¯¯ä¿¡æ¯**ï¼š
```
æ¨¡å‹åŠ è½½å¤±è´¥: æƒé‡æ–‡ä»¶ä¸å­˜åœ¨
```

**è§£å†³æ–¹æ¡ˆ**ï¼š
1. æ£€æŸ¥æƒé‡æ–‡ä»¶è·¯å¾„ï¼š`config.OFFICIAL_WEIGHT_PATH`
2. ç¡®è®¤æƒé‡æ–‡ä»¶å­˜åœ¨ï¼š
   ```bash
   ls -lh static/uploads/weight/official/unet_best_dice0.78.pth
   ```
3. å¦‚æ— å®˜æ–¹æƒé‡ï¼Œä¸Šä¼ è‡ªå®šä¹‰æƒé‡åä½¿ç”¨weight_id

---

### é—®é¢˜4ï¼šæ¸…ç†ä»»åŠ¡æœªå¯åŠ¨

**æ—¥å¿—ä¿¡æ¯**ï¼š
```
[WARNING] âš  å®šæ—¶æ¸…ç†ä»»åŠ¡å¯åŠ¨å¤±è´¥: ...
```

**è§£å†³æ–¹æ¡ˆ**ï¼š
1. æ£€æŸ¥APScheduleræ˜¯å¦å®‰è£…ï¼š`pip list | grep APScheduler`
2. æ£€æŸ¥é…ç½®ï¼š`ENABLE_AUTO_CLEANUP = True`
3. é‡å¯åç«¯æœåŠ¡

---

## ğŸ“Š æ€§èƒ½ä¼˜åŒ–å»ºè®®

### 1. GPUåŠ é€Ÿ

**é…ç½®**ï¼š
```python
# config/config.py
MODEL_DEVICE = "cuda"  # å¼ºåˆ¶ä½¿ç”¨GPU
```

**æ€§èƒ½å¯¹æ¯”**ï¼š
- GPU (CUDA)ï¼š0.05-0.15ç§’/å¼ 
- CPUï¼š0.3-1.0ç§’/å¼ 

---

### 2. æ¨¡å‹ç¼“å­˜

**è¯´æ˜**ï¼šåŒä¸€weight_idçš„å¤šæ¬¡é¢„æµ‹ä¼šè‡ªåŠ¨ä½¿ç”¨ç¼“å­˜ï¼Œæ— éœ€é…ç½®

**æ€§èƒ½æå‡**ï¼š
- é¦–æ¬¡åŠ è½½ï¼š~2ç§’ï¼ˆåŠ è½½æƒé‡ï¼‰
- åç»­é¢„æµ‹ï¼š~0.1ç§’ï¼ˆä½¿ç”¨ç¼“å­˜ï¼‰

---

### 3. æ‰¹é‡é¢„æµ‹

**å»ºè®®**ï¼šå¦‚éœ€å¤„ç†å¤§é‡å›¾åƒï¼Œå¯è€ƒè™‘ï¼š
1. ä½¿ç”¨å¤šè¿›ç¨‹/å¤šçº¿ç¨‹
2. å®ç°æ‰¹é‡é¢„æµ‹æ¥å£ï¼ˆä¸€æ¬¡ä¼ å¤šå¼ å›¾ï¼‰
3. ä½¿ç”¨GPUæ‰¹é‡æ¨ç†ï¼ˆbatch_size>1ï¼‰

---

## ğŸ“ é‡è¦æ–‡ä»¶è·¯å¾„

### æ ¸å¿ƒæ¨¡å—
- `core/weight_validator.py` - æƒé‡æ ¡éªŒ
- `core/model_loader.py` - æ¨¡å‹åŠ è½½
- `core/data_process.py` - æ•°æ®å¤„ç†

### æœåŠ¡å±‚
- `service/prediction_service.py` - é¢„æµ‹æœåŠ¡
- `service/weight_service.py` - æƒé‡ç®¡ç†

### å·¥å…·ç±»
- `utils/logger.py` - æ—¥å¿—é…ç½®
- `utils/cleanup_task.py` - å®šæ—¶æ¸…ç†

### é…ç½®æ–‡ä»¶
- `config/config.py` - ç»Ÿä¸€é…ç½®ç®¡ç†

### æ—¥å¿—æ–‡ä»¶
- `logs/octa_backend.log` - ä¸»æ—¥å¿—æ–‡ä»¶
- `logs/octa_backend.log.1` - å¤‡ä»½1
- ...

### æƒé‡å­˜å‚¨
- `static/uploads/weight/official/` - å®˜æ–¹é¢„ç½®æƒé‡
- `static/uploads/weight/{weight_id}/` - ç”¨æˆ·ä¸Šä¼ æƒé‡

---

## ğŸ“ è¿›é˜¶ç”¨æ³•

### 1. Pythonè„šæœ¬è°ƒç”¨

```python
from pathlib import Path
from service.prediction_service import get_prediction_service

# è·å–é¢„æµ‹æœåŠ¡
service = get_prediction_service()

# æ‰§è¡Œé¢„æµ‹
result = service.predict(
    image_path=Path('uploads/test.png'),
    weight_id='abc123',  # æˆ–Noneä½¿ç”¨å®˜æ–¹æƒé‡
    model_type='unet',
    save_result=True,
    output_dir=Path('results')
)

print(f"æ¨ç†è€—æ—¶: {result['inference_time']}ç§’")
print(f"è¿è¡Œè®¾å¤‡: {result['device']}")
print(f"æ©ç å·²ä¿å­˜: {result['mask_path']}")
```

---

### 2. è‡ªå®šä¹‰é˜ˆå€¼

```python
from core.data_process import get_processor

processor = get_processor()
# åå¤„ç†æ—¶æŒ‡å®šé˜ˆå€¼
mask = processor.postprocess(output_tensor, original_size, threshold=0.3)
```

---

### 3. æ‰‹åŠ¨è§¦å‘æ¸…ç†

```python
from utils.cleanup_task import get_cleanup_task

cleanup = get_cleanup_task()
cleanup.run_now()  # ç«‹å³æ‰§è¡Œä¸€æ¬¡æ¸…ç†
```

---

## ğŸ“ è·å–å¸®åŠ©

**æ–‡æ¡£**ï¼š
- å®Œæ•´ä¼˜åŒ–æŠ¥å‘Šï¼š`BACKEND_OPTIMIZATION_COMPLETE.md`
- APIæ–‡æ¡£ï¼šhttp://127.0.0.1:8000/docsï¼ˆSwagger UIï¼‰

**æ—¥å¿—**ï¼š
- ä¸»æ—¥å¿—ï¼š`logs/octa_backend.log`
- å®æ—¶ç›‘æ§ï¼š`tail -f logs/octa_backend.log`

**é…ç½®**ï¼š
- ç»Ÿä¸€é…ç½®ï¼š`config/config.py`
- æ‰€æœ‰å‚æ•°éƒ½æœ‰è¯¦ç»†æ³¨é‡Š

---

**ç‰ˆæœ¬**ï¼šv1.0  
**æ›´æ–°**ï¼š2026-01-27  
**ç»´æŠ¤**ï¼šOCTA Webé¡¹ç›®ç»„
