# æ–‡ä»¶ç®¡ç†DAOä½¿ç”¨æŒ‡å—

## ğŸ“š æ¦‚è¿°

`file_dao.py` æä¾›äº†å®Œæ•´çš„æ–‡ä»¶ç®¡ç†æ•°æ®åº“CRUDæ“ä½œï¼Œç”¨äºè¿½è¸ªä¸Šä¼ çš„å›¾ç‰‡å’Œæ•°æ®é›†æ–‡ä»¶å…ƒä¿¡æ¯ã€‚

---

## ğŸ—„ï¸ æ•°æ®åº“è¡¨ç»“æ„

### file_management è¡¨

| å­—æ®µå | ç±»å‹ | çº¦æŸ | è¯´æ˜ |
|--------|------|------|------|
| id | INTEGER | PRIMARY KEY, AUTOINCREMENT | è®°å½•ID |
| file_name | TEXT | NOT NULL | åŸå§‹æ–‡ä»¶å |
| file_path | TEXT | NOT NULL | æœ¬åœ°å­˜å‚¨è·¯å¾„ |
| file_type | TEXT | NOT NULL | æ–‡ä»¶ç±»å‹ï¼ˆ'image' æˆ– 'dataset'ï¼‰ |
| upload_time | TIMESTAMP | DEFAULT CURRENT_TIMESTAMP | ä¸Šä¼ æ—¶é—´ |
| related_model | TEXT | NULL | å…³è”æ¨¡å‹æƒé‡è·¯å¾„ |
| file_size | REAL | NULL | æ–‡ä»¶å¤§å°ï¼ˆMBï¼‰ |

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. å¯¼å…¥æ¨¡å—

```python
from dao.file_dao import FileDAO
```

### 2. åˆå§‹åŒ–æ•°æ®åº“ï¼ˆè‡ªåŠ¨æ‰§è¡Œï¼‰

æ¨¡å—å¯¼å…¥æ—¶ä¼šè‡ªåŠ¨åˆ›å»ºè¡¨ï¼Œæ— éœ€æ‰‹åŠ¨è°ƒç”¨ï¼š

```python
# è‡ªåŠ¨æ‰§è¡Œï¼šFileDAO.create_file_table()
```

### 3. æ·»åŠ æ–‡ä»¶è®°å½•

```python
# æ·»åŠ å›¾ç‰‡æ–‡ä»¶
file_id = FileDAO.add_file_record(
    file_name='octa_001.png',
    file_path='uploads/images/octa_001.png',
    file_type='image',
    file_size=2.5
)

# æ·»åŠ æ•°æ®é›†æ–‡ä»¶
dataset_id = FileDAO.add_file_record(
    file_name='training_set.zip',
    file_path='uploads/datasets/training_set.zip',
    file_type='dataset',
    related_model='models/weights/unet_octa.pth',
    file_size=120.8
)
```

### 4. æŸ¥è¯¢æ–‡ä»¶

```python
# æŸ¥è¯¢æ‰€æœ‰æ–‡ä»¶
all_files = FileDAO.get_file_list()

# æŸ¥è¯¢æ‰€æœ‰å›¾ç‰‡
images = FileDAO.get_file_list(file_type='image')

# æŸ¥è¯¢æ‰€æœ‰æ•°æ®é›†
datasets = FileDAO.get_file_list(file_type='dataset')

# æŸ¥è¯¢å•ä¸ªæ–‡ä»¶
file_info = FileDAO.get_file_by_id(1)
```

### 5. æ›´æ–°æ–‡ä»¶å…³è”

```python
# è®­ç»ƒå®Œæˆåæ›´æ–°æ¨¡å‹å…³è”
success = FileDAO.update_file_relation(
    file_id=1,
    related_model='models/weights/unet_trained_20260116.pth'
)
```

### 6. åˆ é™¤æ–‡ä»¶

```python
# åˆ é™¤æ•°æ®åº“è®°å½• + æœ¬åœ°æ–‡ä»¶
success = FileDAO.delete_file(file_id=1)
```

---

## ğŸ“– APIè¯¦ç»†è¯´æ˜

### create_file_table()

**åŠŸèƒ½ï¼š** åˆ›å»ºfile_managementè¡¨ï¼ˆè‹¥ä¸å­˜åœ¨ï¼‰

**è¿”å›ï¼š** `bool` - æˆåŠŸTrueï¼Œå¤±è´¥False

**ç¤ºä¾‹ï¼š**
```python
if FileDAO.create_file_table():
    print("è¡¨åˆ›å»ºæˆåŠŸ")
```

---

### add_file_record()

**åŠŸèƒ½ï¼š** æ·»åŠ æ–‡ä»¶è®°å½•åˆ°æ•°æ®åº“

**å‚æ•°ï¼š**
- `file_name` (str): åŸå§‹æ–‡ä»¶åï¼Œå¿…å¡«
- `file_path` (str): æ–‡ä»¶å­˜å‚¨è·¯å¾„ï¼Œå¿…å¡«
- `file_type` (str): æ–‡ä»¶ç±»å‹ï¼ˆ'image' æˆ– 'dataset'ï¼‰ï¼Œå¿…å¡«
- `related_model` (Optional[str]): å…³è”æ¨¡å‹è·¯å¾„ï¼Œå¯é€‰
- `file_size` (Optional[float]): æ–‡ä»¶å¤§å°ï¼ˆMBï¼‰ï¼Œå¯é€‰

**è¿”å›ï¼š** `Optional[int]` - æˆåŠŸè¿”å›è®°å½•IDï¼Œå¤±è´¥è¿”å›None

**ç¤ºä¾‹ï¼š**
```python
# æœ€ç®€ç¤ºä¾‹
file_id = FileDAO.add_file_record(
    file_name='test.png',
    file_path='uploads/test.png',
    file_type='image'
)

# å®Œæ•´ç¤ºä¾‹
file_id = FileDAO.add_file_record(
    file_name='dataset.zip',
    file_path='uploads/datasets/dataset.zip',
    file_type='dataset',
    related_model='models/weights/unet.pth',
    file_size=50.5
)
```

---

### get_file_list()

**åŠŸèƒ½ï¼š** æŸ¥è¯¢æ–‡ä»¶åˆ—è¡¨ï¼Œæ”¯æŒæŒ‰ç±»å‹ç­›é€‰

**å‚æ•°ï¼š**
- `file_type` (Optional[str]): ç­›é€‰ç±»å‹ï¼ˆNone=å…¨éƒ¨ï¼Œ'image'=å›¾ç‰‡ï¼Œ'dataset'=æ•°æ®é›†ï¼‰

**è¿”å›ï¼š** `List[Dict]` - æ–‡ä»¶è®°å½•åˆ—è¡¨ï¼Œæ¯æ¡è®°å½•ä¸ºå­—å…¸æ ¼å¼

**å­—å…¸æ ¼å¼ï¼š**
```python
{
    'id': 1,
    'file_name': 'test.png',
    'file_path': 'uploads/test.png',
    'file_type': 'image',
    'upload_time': '2026-01-16 10:30:00',
    'related_model': None,
    'file_size': 2.5
}
```

**ç¤ºä¾‹ï¼š**
```python
# æŸ¥è¯¢æ‰€æœ‰æ–‡ä»¶
all_files = FileDAO.get_file_list()
print(f"å…±æœ‰{len(all_files)}ä¸ªæ–‡ä»¶")

# æŸ¥è¯¢æ‰€æœ‰å›¾ç‰‡
images = FileDAO.get_file_list(file_type='image')
for img in images:
    print(f"{img['file_name']}: {img['file_size']} MB")

# æŸ¥è¯¢æ‰€æœ‰æ•°æ®é›†
datasets = FileDAO.get_file_list(file_type='dataset')
for ds in datasets:
    print(f"{ds['file_name']} -> {ds['related_model']}")
```

---

### get_file_by_id()

**åŠŸèƒ½ï¼š** æŒ‰IDæŸ¥è¯¢å•ä¸ªæ–‡ä»¶ä¿¡æ¯

**å‚æ•°ï¼š**
- `file_id` (int): æ–‡ä»¶è®°å½•ID

**è¿”å›ï¼š** `Optional[Dict]` - æ‰¾åˆ°è¿”å›å­—å…¸ï¼Œæœªæ‰¾åˆ°è¿”å›None

**ç¤ºä¾‹ï¼š**
```python
file_info = FileDAO.get_file_by_id(1)

if file_info:
    print(f"æ–‡ä»¶å: {file_info['file_name']}")
    print(f"æ–‡ä»¶å¤§å°: {file_info['file_size']} MB")
    print(f"ä¸Šä¼ æ—¶é—´: {file_info['upload_time']}")
else:
    print("æ–‡ä»¶ä¸å­˜åœ¨")
```

---

### update_file_relation()

**åŠŸèƒ½ï¼š** æ›´æ–°æ–‡ä»¶å…³è”çš„æ¨¡å‹æƒé‡

**å‚æ•°ï¼š**
- `file_id` (int): æ–‡ä»¶è®°å½•ID
- `related_model` (str): æ¨¡å‹æƒé‡æ–‡ä»¶è·¯å¾„

**è¿”å›ï¼š** `bool` - æˆåŠŸTrueï¼Œå¤±è´¥False

**ä½¿ç”¨åœºæ™¯ï¼š** è®­ç»ƒå®Œæˆåï¼Œå°†è®­ç»ƒä½¿ç”¨çš„æ•°æ®é›†ä¸ç”Ÿæˆçš„æ¨¡å‹æƒé‡å»ºç«‹å…³è”

**ç¤ºä¾‹ï¼š**
```python
# è®­ç»ƒå®Œæˆåå…³è”æ¨¡å‹
success = FileDAO.update_file_relation(
    file_id=1,
    related_model='models/weights/unet_trained_20260116.pth'
)

if success:
    print("æ¨¡å‹å…³è”æ›´æ–°æˆåŠŸ")
```

---

### delete_file()

**åŠŸèƒ½ï¼š** åˆ é™¤æ–‡ä»¶è®°å½•å’Œæœ¬åœ°æ–‡ä»¶

**å‚æ•°ï¼š**
- `file_id` (int): è¦åˆ é™¤çš„æ–‡ä»¶è®°å½•ID

**è¿”å›ï¼š** `bool` - æˆåŠŸTrueï¼Œå¤±è´¥False

**æ‰§è¡Œæ­¥éª¤ï¼š**
1. æŸ¥è¯¢æ–‡ä»¶è·¯å¾„
2. åˆ é™¤æ•°æ®åº“è®°å½•
3. åˆ é™¤æœ¬åœ°æ–‡ä»¶æˆ–ç›®å½•

**ç‰¹æ€§ï¼š**
- è‡ªåŠ¨åŒºåˆ†æ–‡ä»¶å’Œç›®å½•ï¼ˆç›®å½•ä½¿ç”¨shutil.rmtreeé€’å½’åˆ é™¤ï¼‰
- è·¯å¾„å­˜åœ¨æ€§æ ¡éªŒï¼ˆé¿å…FileNotFoundErrorï¼‰
- æ•°æ®åº“ä¸æ–‡ä»¶ç³»ç»ŸåŒæ­¥

**ç¤ºä¾‹ï¼š**
```python
# åˆ é™¤å•ä¸ªæ–‡ä»¶
if FileDAO.delete_file(1):
    print("æ–‡ä»¶åˆ é™¤æˆåŠŸ")
else:
    print("æ–‡ä»¶åˆ é™¤å¤±è´¥")
```

---

## ğŸ¯ å®é™…åº”ç”¨åœºæ™¯

### åœºæ™¯1ï¼šæ–‡ä»¶ä¸Šä¼ å¤„ç†

```python
from fastapi import UploadFile
from dao.file_dao import FileDAO
import os

async def handle_file_upload(file: UploadFile, file_type: str):
    """å¤„ç†æ–‡ä»¶ä¸Šä¼ """
    
    # ä¿å­˜æ–‡ä»¶åˆ°æœ¬åœ°
    save_path = f"uploads/{file_type}s/{file.filename}"
    with open(save_path, 'wb') as f:
        content = await file.read()
        f.write(content)
    
    # è®¡ç®—æ–‡ä»¶å¤§å°ï¼ˆMBï¼‰
    file_size = len(content) / (1024 * 1024)
    
    # æ·»åŠ æ•°æ®åº“è®°å½•
    file_id = FileDAO.add_file_record(
        file_name=file.filename,
        file_path=save_path,
        file_type=file_type,
        file_size=file_size
    )
    
    return {
        'file_id': file_id,
        'file_name': file.filename,
        'file_size': file_size
    }
```

### åœºæ™¯2ï¼šæ–‡ä»¶åˆ—è¡¨å±•ç¤º

```python
from dao.file_dao import FileDAO

def get_file_management_page():
    """è·å–æ–‡ä»¶ç®¡ç†é¡µé¢æ•°æ®"""
    
    # è·å–æ‰€æœ‰æ–‡ä»¶
    all_files = FileDAO.get_file_list()
    
    # ç»Ÿè®¡ä¿¡æ¯
    total_count = len(all_files)
    image_count = len([f for f in all_files if f['file_type'] == 'image'])
    dataset_count = len([f for f in all_files if f['file_type'] == 'dataset'])
    total_size = sum(f['file_size'] or 0 for f in all_files)
    
    return {
        'files': all_files,
        'statistics': {
            'total_count': total_count,
            'image_count': image_count,
            'dataset_count': dataset_count,
            'total_size_mb': round(total_size, 2)
        }
    }
```

### åœºæ™¯3ï¼šæ¨¡å‹è®­ç»ƒæµç¨‹

```python
from dao.file_dao import FileDAO

def train_model_workflow(dataset_id: int):
    """æ¨¡å‹è®­ç»ƒæµç¨‹"""
    
    # 1. è·å–æ•°æ®é›†ä¿¡æ¯
    dataset_info = FileDAO.get_file_by_id(dataset_id)
    if not dataset_info:
        raise ValueError(f"æ•°æ®é›†ä¸å­˜åœ¨: {dataset_id}")
    
    dataset_path = dataset_info['file_path']
    
    # 2. è®­ç»ƒæ¨¡å‹
    model = train_model(dataset_path)
    
    # 3. ä¿å­˜æ¨¡å‹æƒé‡
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    model_path = f'models/weights/unet_{timestamp}.pth'
    save_model(model, model_path)
    
    # 4. æ›´æ–°æ•°æ®é›†å…³è”
    success = FileDAO.update_file_relation(dataset_id, model_path)
    
    if success:
        print(f"è®­ç»ƒå®Œæˆï¼Œæ¨¡å‹ä¿å­˜è‡³: {model_path}")
    
    return model_path
```

### åœºæ™¯4ï¼šæ–‡ä»¶æ¸…ç†

```python
from dao.file_dao import FileDAO
from datetime import datetime, timedelta

def cleanup_old_files(days: int = 30):
    """æ¸…ç†è¶…è¿‡æŒ‡å®šå¤©æ•°çš„æ–‡ä»¶"""
    
    # è·å–æ‰€æœ‰æ–‡ä»¶
    all_files = FileDAO.get_file_list()
    
    # è®¡ç®—æˆªæ­¢æ—¶é—´
    cutoff_date = datetime.now() - timedelta(days=days)
    
    deleted_count = 0
    for file in all_files:
        # è§£æä¸Šä¼ æ—¶é—´
        upload_time = datetime.strptime(file['upload_time'], '%Y-%m-%d %H:%M:%S')
        
        # å¦‚æœè¶…è¿‡æŒ‡å®šå¤©æ•°ï¼Œåˆ é™¤
        if upload_time < cutoff_date:
            if FileDAO.delete_file(file['id']):
                deleted_count += 1
                print(f"å·²åˆ é™¤: {file['file_name']}")
    
    print(f"å…±æ¸…ç†{deleted_count}ä¸ªè¿‡æœŸæ–‡ä»¶")
    return deleted_count
```

---

## âš ï¸ æ³¨æ„äº‹é¡¹

### 1. æ–‡ä»¶ç±»å‹éªŒè¯

æ–‡ä»¶ç±»å‹å¿…é¡»ä¸º `'image'` æˆ– `'dataset'`ï¼Œå¦åˆ™ä¼šè¢«æ‹’ç»ï¼š

```python
# âœ“ æ­£ç¡®
FileDAO.add_file_record(..., file_type='image')
FileDAO.add_file_record(..., file_type='dataset')

# âœ— é”™è¯¯
FileDAO.add_file_record(..., file_type='video')  # ä¼šè¿”å›None
```

### 2. æ–‡ä»¶è·¯å¾„ç®¡ç†

å»ºè®®ä½¿ç”¨ç›¸å¯¹è·¯å¾„ï¼Œä¾¿äºé¡¹ç›®è¿ç§»ï¼š

```python
# âœ“ æ¨èï¼šç›¸å¯¹è·¯å¾„
file_path='uploads/images/test.png'

# âœ— ä¸æ¨èï¼šç»å¯¹è·¯å¾„ï¼ˆä¸åˆ©äºè¿ç§»ï¼‰
file_path='D:/Code/OCTA_Web/uploads/images/test.png'
```

### 3. æ–‡ä»¶åˆ é™¤åŒæ­¥

`delete_file()` ä¼šåŒæ­¥åˆ é™¤æ•°æ®åº“è®°å½•å’Œæœ¬åœ°æ–‡ä»¶ï¼š

```python
# åˆ é™¤æ“ä½œåŒ…æ‹¬ï¼š
# 1. åˆ é™¤æ•°æ®åº“è®°å½•
# 2. åˆ é™¤æœ¬åœ°æ–‡ä»¶/ç›®å½•

success = FileDAO.delete_file(1)
# å¦‚æœæœ¬åœ°æ–‡ä»¶ä¸å­˜åœ¨ï¼Œä»ç„¶ä¼šåˆ é™¤æ•°æ®åº“è®°å½•
```

### 4. å¼‚å¸¸å¤„ç†

æ‰€æœ‰å‡½æ•°éƒ½æœ‰å®Œå–„çš„å¼‚å¸¸å¤„ç†ï¼Œå¤±è´¥æ—¶è¿”å›Falseæˆ–Noneï¼š

```python
# æ·»åŠ è®°å½•å¤±è´¥è¿”å›None
file_id = FileDAO.add_file_record(...)
if not file_id:
    print("æ·»åŠ å¤±è´¥")

# æŸ¥è¯¢å¤±è´¥è¿”å›Noneæˆ–ç©ºåˆ—è¡¨
file_info = FileDAO.get_file_by_id(999)
if not file_info:
    print("æ–‡ä»¶ä¸å­˜åœ¨")

# åˆ é™¤å¤±è´¥è¿”å›False
success = FileDAO.delete_file(999)
if not success:
    print("åˆ é™¤å¤±è´¥")
```

---

## ğŸ” è°ƒè¯•æŠ€å·§

### æŸ¥çœ‹SQLæ—¥å¿—

æ‰€æœ‰å‡½æ•°éƒ½ä¼šæ‰“å°è¯¦ç»†æ—¥å¿—ï¼š

```
[SUCCESS] æ–‡ä»¶è®°å½•æ·»åŠ æˆåŠŸ
[INFO] è®°å½•ID: 1
[INFO] æ–‡ä»¶å: test.png
[INFO] æ–‡ä»¶ç±»å‹: image
[INFO] æ–‡ä»¶å¤§å°: 2.5 MB
```

### æ•°æ®åº“è·¯å¾„

é»˜è®¤ä½¿ç”¨ `./octa.db`ï¼Œå¯åœ¨ `config/config.py` ä¸­ä¿®æ”¹ï¼š

```python
# config/config.py
DB_PATH = "./octa.db"
```

### ç›´æ¥æŸ¥è¯¢æ•°æ®åº“

```bash
# ä½¿ç”¨SQLiteå‘½ä»¤è¡Œå·¥å…·
sqlite3 octa.db

# æŸ¥çœ‹è¡¨ç»“æ„
.schema file_management

# æŸ¥è¯¢æ‰€æœ‰è®°å½•
SELECT * FROM file_management;

# é€€å‡º
.quit
```

---

## ğŸ“Š æ€§èƒ½å»ºè®®

### 1. æ‰¹é‡æŸ¥è¯¢

æŸ¥è¯¢æ‰€æœ‰æ–‡ä»¶ååœ¨å†…å­˜ä¸­ç­›é€‰ï¼Œé¿å…å¤šæ¬¡æ•°æ®åº“æŸ¥è¯¢ï¼š

```python
# âœ“ æ¨èï¼šä¸€æ¬¡æŸ¥è¯¢ï¼Œå†…å­˜ç­›é€‰
all_files = FileDAO.get_file_list()
images = [f for f in all_files if f['file_type'] == 'image']
datasets = [f for f in all_files if f['file_type'] == 'dataset']

# âœ— ä¸æ¨èï¼šå¤šæ¬¡æ•°æ®åº“æŸ¥è¯¢
images = FileDAO.get_file_list(file_type='image')
datasets = FileDAO.get_file_list(file_type='dataset')
```

### 2. ç¼“å­˜æ–‡ä»¶åˆ—è¡¨

å‰ç«¯å±•ç¤ºæ—¶å¯ä»¥ç¼“å­˜æ–‡ä»¶åˆ—è¡¨ï¼Œå‡å°‘æ•°æ®åº“æŸ¥è¯¢ï¼š

```python
from functools import lru_cache

@lru_cache(maxsize=1)
def get_cached_file_list():
    return FileDAO.get_file_list()

# æ¸…é™¤ç¼“å­˜ï¼ˆæ–‡ä»¶æ›´æ–°åï¼‰
get_cached_file_list.cache_clear()
```

---

## ğŸ§ª æµ‹è¯•

è¿è¡Œæµ‹è¯•è„šæœ¬éªŒè¯åŠŸèƒ½ï¼š

```bash
cd octa_backend
python test_file_dao.py
```

æµ‹è¯•å†…å®¹ï¼š
- âœ“ æ•°æ®åº“è¡¨åˆ›å»º
- âœ“ æ·»åŠ æ–‡ä»¶è®°å½•ï¼ˆå›¾ç‰‡å’Œæ•°æ®é›†ï¼‰
- âœ“ æŸ¥è¯¢æ‰€æœ‰æ–‡ä»¶
- âœ“ æŒ‰ç±»å‹ç­›é€‰æŸ¥è¯¢
- âœ“ æŒ‰IDæŸ¥è¯¢å•ä¸ªæ–‡ä»¶
- âœ“ æ›´æ–°æ–‡ä»¶å…³è”æ¨¡å‹
- âœ“ åˆ é™¤æ–‡ä»¶è®°å½•å’Œæœ¬åœ°æ–‡ä»¶
- âœ“ å¼‚å¸¸æƒ…å†µå¤„ç†

---

## ğŸ“ æ€»ç»“

**æ ¸å¿ƒåŠŸèƒ½ï¼š**
- âœ… å®Œæ•´çš„CRUDæ“ä½œ
- âœ… æ–‡ä»¶ç±»å‹åˆ†ç±»ç®¡ç†
- âœ… æ¨¡å‹å…³è”è¿½è¸ª
- âœ… æ•°æ®åº“ä¸æ–‡ä»¶ç³»ç»ŸåŒæ­¥
- âœ… å®Œå–„çš„å¼‚å¸¸å¤„ç†

**ä½¿ç”¨åœºæ™¯ï¼š**
- æ–‡ä»¶ä¸Šä¼ ç®¡ç†
- æ–‡ä»¶åˆ—è¡¨å±•ç¤º
- æ¨¡å‹è®­ç»ƒè¿½è¸ª
- æ–‡ä»¶æ¸…ç†ç»´æŠ¤

**æŠ€æœ¯ç‰¹ç‚¹ï¼š**
- é™æ€æ–¹æ³•è®¾è®¡ï¼Œæ— éœ€å®ä¾‹åŒ–
- æ‰€æœ‰æ“ä½œè‡ªåŠ¨å…³é—­æ•°æ®åº“è¿æ¥
- å‹å¥½çš„é”™è¯¯æç¤ºå’Œæ—¥å¿—
- æ”¯æŒæ–‡ä»¶å’Œç›®å½•åˆ é™¤

---

**ä½œè€…ï¼š** OCTA Webé¡¹ç›®ç»„  
**æ—¥æœŸï¼š** 2026å¹´1æœˆ16æ—¥
